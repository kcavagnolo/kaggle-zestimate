{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0c2520a-71c8-c705-b362-7844e4b25b79"
   },
   "source": [
    "The following notebook introduces ML-Ensemble, a Python library for memory-efficient parallel ensemble learning with a Scikit-learn API. \n",
    "\n",
    "ML-Ensemble also deploys a neural network-like API for building ensembles of several layers, and can accomodate a great variety of ensemble architectures. \n",
    "\n",
    "For more information, see http://mlens.readthedocs.io/en/latest/index.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1fed8d6f-4c44-b4c7-363b-2ff9e6a594c3"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inputs\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data viz\n",
    "from mlens.visualization import corr_X_y, corrmat\n",
    "\n",
    "# Model evaluation\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.preprocessing import EnsembleTransformer\n",
    "\n",
    "# Ensemble\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "0a509d0f-ab3f-5e19-97ad-c88ed75bd393"
   },
   "outputs": [],
   "source": [
    "SEED = 148\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "082bc8ab-5880-8b96-f57c-1429432be317"
   },
   "source": [
    "# 1. Getting a good baseline for ensemble learning\n",
    "\n",
    "It's always good to check how inputs play along with the output.\n",
    "Here, we highlight one example functionality of the Ml-Ensemble's\n",
    "visualization library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "96d981c5-a6a1-1e62-9bad-9aac5197f769"
   },
   "outputs": [],
   "source": [
    "def build_train():\n",
    "    \"\"\"Read in training data and return input, output, columns tuple.\"\"\"\n",
    "\n",
    "    # This is a version of Anovas minimally prepared dataset\n",
    "    # for the xgbstarter script\n",
    "    # https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n",
    "\n",
    "    df = pd.read_csv('../input/train_2016.csv')\n",
    "\n",
    "    prop = pd.read_csv('../input/properties_2016.csv')\n",
    "    convert = prop.dtypes == 'float64'\n",
    "    prop.loc[:, convert] = \\\n",
    "        prop.loc[:, convert].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    df = df.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "    y = df.logerror\n",
    "    df = df.drop(['parcelid',\n",
    "                  'logerror',\n",
    "                  'transactiondate',\n",
    "                  'propertyzoningdesc',\n",
    "                  'taxdelinquencyflag',\n",
    "                  'propertycountylandusecode'], axis=1)\n",
    "\n",
    "    convert = df.dtypes == 'object'\n",
    "    df.loc[:, convert] = \\\n",
    "        df.loc[:, convert].apply(lambda x: 1 * (x == True))\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df, y, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "9d067d92-4703-d61b-5432-e9e58def803e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain, columns = build_train()\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xtrain,\n",
    "                                                ytrain,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b0e7fe89-12b7-eab5-d270-b2128313afa9"
   },
   "outputs": [],
   "source": [
    "# this plot requires mlens 0.1.3, Kaggle is currently on 0.1.2\n",
    "#corr_X_y(xtrain, ytrain, figsize=(16, 10), label_rotation=80, hspace=1, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "91c81883-5c34-2ca4-afc1-bf95534bae26"
   },
   "source": [
    "A few features seems to be (first-order) uncorrelated with the output, suggesting estimators with inherent\n",
    "feature selection should be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "278631f6-4a65-dda2-cbf1-82965ea6b893"
   },
   "source": [
    "Now, consider how set of base learners (estimators) perform as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "299d7916-8391-5a21-db3b-ac5014eb925e"
   },
   "outputs": [],
   "source": [
    "# We consider the following models (or base learners)\n",
    "gb = XGBRegressor(n_jobs=1, random_state=SEED)\n",
    "ls = Lasso(alpha=1e-6, normalize=True)\n",
    "el = ElasticNet(alpha=1e-6, normalize=True)\n",
    "rf = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "base_learners = [('ls', ls),\n",
    "                 ('el', el),\n",
    "                 ('rf', rf),\n",
    "                 ('gb', gb)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "5d46059c-2c3c-b383-dd3f-0b129c4cf1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ls : 0.0700\n",
      " el : 0.0700\n",
      " rf : 0.0830\n",
      " gb : 0.0702\n"
     ]
    }
   ],
   "source": [
    "P = np.zeros((xtest.shape[0], len(base_learners)))\n",
    "P = pd.DataFrame(P, columns=[e for e, _ in base_learners])\n",
    "\n",
    "for est_name, est in base_learners:\n",
    "    est.fit(xtrain, ytrain)\n",
    "    p = est.predict(xtest)\n",
    "    P.loc[:, est_name] = p\n",
    "    print(\"%3s : %.4f\" % (est_name, mean_absolute_error(ytest, p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e180babd-e852-60ec-319d-c704606b4f71"
   },
   "source": [
    "So they all score relatively close. However, they seem to capture different aspects of the feature space, as shown by the low correlation of their predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "9ecb9ad7-5d71-0d26-3f6c-5b49ebb15cc6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAIZCAYAAABtQNHcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f950ab49a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = corrmat(P.corr())\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75fc44d9-540a-d669-4f0f-2307fb1387d6"
   },
   "source": [
    "They are in fact not particularly correlated in their scoring (except the linear models), and hence\n",
    "an ensemble may be able to outperform any single model by learning to combine their respective strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a1b054d0-9385-26ad-be38-4f22c89e113a"
   },
   "source": [
    "## 2. Comparing base learners\n",
    "\n",
    "*emphasized text*To facilitate base learner comparison, ML-Ensemble implements a randomized grid search\n",
    "class that allows specification of several estimators (and preprocessing pipelines) in\n",
    "one grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "3f4fbe54-a250-e0fd-fcde-821228da7c18"
   },
   "outputs": [],
   "source": [
    "# Put their parameter dictionaries in a dictionary with the\n",
    "# estimator names as keys\n",
    "param_dicts = {'ls':\n",
    "                  {'alpha': uniform(1e-6, 1e-5)},\n",
    "               'el':\n",
    "                  {'alpha': uniform(1e-6, 1e-5),\n",
    "                   'l1_ratio': uniform(0, 1)},\n",
    "               'gb':\n",
    "                   {'learning_rate': uniform(0.02, 0.04),\n",
    "                    'colsample_bytree': uniform(0.55, 0.66),\n",
    "                    'min_child_weight': randint(30, 60),\n",
    "                    'max_depth': randint(3, 7),\n",
    "                    'subsample': uniform(0.4, 0.2),\n",
    "                    'n_estimators': randint(150, 200),\n",
    "                    'colsample_bytree': uniform(0.6, 0.4),\n",
    "                    'reg_lambda': uniform(1, 2),\n",
    "                    'reg_alpha': uniform(1, 2),\n",
    "                   },\n",
    "               'rf':\n",
    "                   {'max_depth': randint(2, 5),\n",
    "                    'min_samples_split': randint(5, 20),\n",
    "                    'min_samples_leaf': randint(10, 20),\n",
    "                    'n_estimators': randint(50, 100),\n",
    "                    'max_features': uniform(0.6, 0.3)}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "3fd0c5c9-c9fe-2465-6341-9f54d899346f"
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "evl = Evaluator(scorer,\n",
    "                cv=2,\n",
    "                random_state=SEED,\n",
    "                verbose=5,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "7dfd3238-b31d-6577-0613-0a71abaf95da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing 2 preprocessing pipelines over 2 CV folds\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "Preprocessing done | 00:00:00\n",
      "\n",
      "Evaluating 8 models for 2 parameter draws over 2 preprocessing pipelines and 2 CV folds, totalling 32 fits\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  32 | elapsed:  1.4min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  32 | elapsed:  2.3min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  32 | elapsed:  2.8min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  32 | elapsed:  3.0min remaining:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:  3.1min finished\n",
      "Evaluation done | 00:03:04\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x7f950a0b5748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.fit(xtrain.values,  # you can pass DataFrames from mlens>=0.1.3 \n",
    "        ytrain.values,\n",
    "        estimators=base_learners,\n",
    "        param_dicts=param_dicts,\n",
    "        preprocessing={'sc': [StandardScaler()], 'none': []},\n",
    "        n_iter=2)  # bump this up to do a larger grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79510c7f-0465-e19f-1c70-6cc3d846f3c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_score_mean</th>\n",
       "      <th>test_score_std</th>\n",
       "      <th>train_score_mean</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">none</th>\n",
       "      <th>el</th>\n",
       "      <td>-0.068625</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.068500</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>55.798629</td>\n",
       "      <td>0.505549</td>\n",
       "      <td>{'alpha': 6.75405852231e-06, 'l1_ratio': 0.575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>-0.069221</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.067237</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>147.977106</td>\n",
       "      <td>17.780799</td>\n",
       "      <td>{'learning_rate': 0.0430162340892, 'colsample_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls</th>\n",
       "      <td>-0.068597</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>110.635388</td>\n",
       "      <td>17.663798</td>\n",
       "      <td>{'alpha': 6.75405852231e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>-0.068539</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-0.068243</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>60.777791</td>\n",
       "      <td>18.825366</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 8, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sc</th>\n",
       "      <th>el</th>\n",
       "      <td>-0.068625</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.068500</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>43.303480</td>\n",
       "      <td>5.799169</td>\n",
       "      <td>{'alpha': 6.75405852231e-06, 'l1_ratio': 0.575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>-0.069237</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.067224</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>71.490409</td>\n",
       "      <td>26.763778</td>\n",
       "      <td>{'learning_rate': 0.0430162340892, 'colsample_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls</th>\n",
       "      <td>-0.068597</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>54.944063</td>\n",
       "      <td>18.751625</td>\n",
       "      <td>{'alpha': 6.75405852231e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>-0.068539</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-0.068243</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>70.845631</td>\n",
       "      <td>24.645965</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 8, 'min_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score_mean  test_score_std  train_score_mean  train_score_std  \\\n",
       "none el        -0.068625        0.000297         -0.068500         0.000331   \n",
       "     gb        -0.069221        0.000074         -0.067237         0.000331   \n",
       "     ls        -0.068597        0.000296         -0.068491         0.000342   \n",
       "     rf        -0.068539        0.000270         -0.068243         0.000269   \n",
       "sc   el        -0.068625        0.000297         -0.068500         0.000331   \n",
       "     gb        -0.069237        0.000069         -0.067224         0.000334   \n",
       "     ls        -0.068597        0.000296         -0.068491         0.000342   \n",
       "     rf        -0.068539        0.000270         -0.068243         0.000269   \n",
       "\n",
       "         fit_time_mean  fit_time_std  \\\n",
       "none el      55.798629      0.505549   \n",
       "     gb     147.977106     17.780799   \n",
       "     ls     110.635388     17.663798   \n",
       "     rf      60.777791     18.825366   \n",
       "sc   el      43.303480      5.799169   \n",
       "     gb      71.490409     26.763778   \n",
       "     ls      54.944063     18.751625   \n",
       "     rf      70.845631     24.645965   \n",
       "\n",
       "                                                    params  \n",
       "none el  {'alpha': 6.75405852231e-06, 'l1_ratio': 0.575...  \n",
       "     gb  {'learning_rate': 0.0430162340892, 'colsample_...  \n",
       "     ls                       {'alpha': 6.75405852231e-06}  \n",
       "     rf  {'max_depth': 4, 'min_samples_split': 8, 'min_...  \n",
       "sc   el  {'alpha': 6.75405852231e-06, 'l1_ratio': 0.575...  \n",
       "     gb  {'learning_rate': 0.0430162340892, 'colsample_...  \n",
       "     ls                       {'alpha': 6.75405852231e-06}  \n",
       "     rf  {'max_depth': 4, 'min_samples_split': 8, 'min_...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1074dc1-70ea-4fee-5746-9d22fab75ffd"
   },
   "source": [
    "There you have it, a comparison of tuned models in one grid search!\n",
    "\n",
    "Optimal parameters are then easily accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "a56f93f3-7f61-e402-dd4e-084e7e542f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.83016234089249397,\n",
       " 'learning_rate': 0.0430162340892494,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 49,\n",
       " 'n_estimators': 169,\n",
       " 'reg_alpha': 2.1508117044624697,\n",
       " 'reg_lambda': 2.1508117044624697,\n",
       " 'subsample': 0.51508117044624702}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.summary[\"params\"][('sc', 'gb')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2b8820aa-85fe-7d5f-9697-9a7ac528007c"
   },
   "source": [
    "# 3. Comparing meta learners\n",
    "\n",
    "Running an entire ensemble several times just to compare different meta learners can be prohibitvely expensive. ML-Ensemble implements a class that acts as a transformer, allowing you to use ingoing layers as a \"preprocessing\" step, so that you need only evaluate the meta learners iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "38156447-69dd-9bc5-2f68-e9f1f59aebc0"
   },
   "outputs": [],
   "source": [
    "for case_name, params in evl.summary[\"params\"].items():\n",
    "    for est_name, est in base_learners:\n",
    "        if est_name == case_name[1]:\n",
    "            est.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "7b29ad65-eee3-b75c-7865-10bfbda05b54"
   },
   "outputs": [],
   "source": [
    "# We will compare a GBM and an elastic net as the meta learner\n",
    "# These are cloned internally so we can go ahead and grab the fitted ones\n",
    "meta_learners = [('gb', gb),\n",
    "                 ('el', el)]\n",
    "\n",
    "# Note that when we have a preprocessing pipeline,\n",
    "# keys are in the (prep_name, est_name) format\n",
    "param_dicts = {'el':\n",
    "                  {'alpha': uniform(1e-5, 1),\n",
    "                   'l1_ratio': uniform(0, 1)},\n",
    "               'gb':\n",
    "                   {'learning_rate': uniform(0.01, 0.2),\n",
    "                    'subsample': uniform(0.5, 0.5),\n",
    "                    'reg_lambda': uniform(0.1, 1),\n",
    "                    'n_estimators': randint(10, 100)},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "d1230a30-cc93-ffc7-a0e5-2afeacee6577"
   },
   "outputs": [],
   "source": [
    "# Here, we but the base learners in an EnsembleTransformer class\n",
    "# this class will faithfully reproduce predictions for each fold\n",
    "# in a cross-validation execution as if it was the first n layers\n",
    "# of an ensemble\n",
    "\n",
    "# The API of the Ensemble transformer mirrors that of the SequentialEnsemble class,\n",
    "# see documentation for further info\n",
    "in_layer = EnsembleTransformer()\n",
    "in_layer.add('stack', base_learners)\n",
    "\n",
    "preprocess = [in_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "fdaef90c-8b4e-ec0a-49b1-221ddc026300"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing 1 preprocessing pipelines over 2 CV folds\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   33.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   33.6s finished\n",
      "Preprocessing done | 00:00:34\n",
      "\n",
      "Evaluating 2 models for 20 parameter draws over 1 preprocessing pipelines and 2 CV folds, totalling 80 fits\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  80 | elapsed:  1.6min remaining:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.8min finished\n",
      "Evaluation done | 00:01:45\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x7f950a0b5748>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.fit(xtrain.values,\n",
    "        ytrain.values,\n",
    "        meta_learners,\n",
    "        param_dicts,\n",
    "        preprocessing={'meta': preprocess},\n",
    "        n_iter=20                            # bump this up to do a larger grid search\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "42e4b794-8ecc-4419-abb7-a682c0cf551b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_score_mean</th>\n",
       "      <th>test_score_std</th>\n",
       "      <th>train_score_mean</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">meta</th>\n",
       "      <th>el</th>\n",
       "      <td>-0.068670</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.068670</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.245040</td>\n",
       "      <td>0.242613</td>\n",
       "      <td>{'alpha': 0.575415852231, 'l1_ratio': 0.575405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>-0.069084</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>-0.068542</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>2.638875</td>\n",
       "      <td>0.344644</td>\n",
       "      <td>{'learning_rate': 0.123474273812, 'subsample':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score_mean  test_score_std  train_score_mean  train_score_std  \\\n",
       "meta el        -0.068670        0.000350         -0.068670         0.000337   \n",
       "     gb        -0.069084        0.000205         -0.068542         0.000316   \n",
       "\n",
       "         fit_time_mean  fit_time_std  \\\n",
       "meta el       0.245040      0.242613   \n",
       "     gb       2.638875      0.344644   \n",
       "\n",
       "                                                    params  \n",
       "meta el  {'alpha': 0.575415852231, 'l1_ratio': 0.575405...  \n",
       "     gb  {'learning_rate': 0.123474273812, 'subsample':...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64e69cf0-aee4-c65a-f9ce-d58b370066c9"
   },
   "source": [
    "# 4. Ensemble learning\n",
    "\n",
    "With these results in mind, we now turn to building an ensemble estimator.\n",
    "\n",
    "ML-Ensemble uses a neural network-like API to specify layers of base learners to be\n",
    "fitted sequentially on the previous layer's predictions (or the raw input for the\n",
    "first layer). An ensemble is built as a Scikit-learn estimator, and can be used as\n",
    "any other Scikit-learn class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "d7440c1d-f3a5-a001-b4f1-82c20f4229cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.57541585223123481, copy_X=True, fit_intercept=True,\n",
       "      l1_ratio=0.57540585223123486, max_iter=1000, normalize=True,\n",
       "      positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick the linear meta learner with the above tuned\n",
    "# hyper-parameters. Note that ideally, you'd want to tune\n",
    "# the ensemble as a whole, not each estimator at a time\n",
    "meta_learner = meta_learners[1][1]\n",
    "\n",
    "meta_learner.set_params(**evl.summary[\"params\"][(\"meta\", \"el\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ff3192d-5cd4-b8fa-8b4f-45b6d2bf4cbe"
   },
   "source": [
    "The ensemble we will implement is the Super Learner, also known as a stacking ensemble. There are several alternatives, see the documentation for further info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "23308d6c-50a5-1b31-58ce-e24e166b0eed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('ls', Lasso(alpha=6.7540585223123488e-06, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=True, positive=False, precompute=False,\n",
       "   random_state=None, ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the ensemble by adding layers to it. Finalize with a meta layer\n",
    "ens = SuperLearner(verbose=5,\n",
    "                   backend=\"threading\") # mlens can release the GIL\n",
    "ens.add(base_learners)\n",
    "ens.add_meta(meta_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43b2ba6d-cf90-3de4-be58-a078fb01a1ee"
   },
   "source": [
    "Once instantiated, the ensemble will behave like any other Scikit-learn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "f0f797a6-d467-5d5f-23a4-badc954e85ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:    1.9s remaining:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:   11.6s remaining:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:   23.8s remaining:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   43.2s finished\n",
      "layer-1 Done | 00:00:42\n",
      "\n",
      "Fitting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete | 00:00:42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend='threading', folds=2,\n",
       "       layers=LayerContainer(backend='threading',\n",
       "        layers=OrderedDict([('layer-1', Layer(cls='stack', cls_kwargs=None,\n",
       "   estimators=[('ls', Lasso(alpha=6.7540585223123488e-06, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=True, positive=False, precompute=False,\n",
       "   random_state=None, ...n_exception=True, scorer=None, verbose=5))]),\n",
       "        n_jobs=-1, raise_on_exception=True, verbose=5),\n",
       "       n_jobs=-1, raise_on_exception=True, random_state=None, scorer=None,\n",
       "       shuffle=False, verbose=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "032e87cd-d503-03dd-e5e8-bb466d2a3fa4"
   },
   "source": [
    "Predictions are generated as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "3c64a85a-816c-3954-d5e2-c3b3b818bbc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layers (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting layer-1\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done | 00:00:01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s finished\n",
      "layer-1 Done | 00:00:00\n",
      "\n",
      "Predicting layer-2\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "layer-2 Done | 00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = ens.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "2513f179-ea59-653e-7b4b-84084e64eaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble score: 0.0700\n"
     ]
    }
   ],
   "source": [
    "print(\"ensemble score: %.4f\" % mean_absolute_error(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ee96c61-675a-5428-b4b3-19991a8780be"
   },
   "source": [
    "And that's it for this tutorial!\n",
    "\n",
    "You might have noticed that the ensemble did not achieve an increase in performance. This is partly due to the lack of proper hyper parameter tuning, but more importantly because the base learners are not sufficiently accurate for there to be anything meaningful for the meta learner to learn from (note that predicting the average gets you about 0.07) \n",
    "\n",
    "In these cases, unless the meta learner is underfitting, the ensemble will at least be on par with the best base learner.  Good features are always the primary source of predictive power. Once you have them, combining different estimators in an ensemble is a powerful way of learning as much of the signal in the data as possible.\n",
    "\n",
    "If you decide to give ML-Ensemble a try, note that the library is in beta testing so you may run into some unexpected behavior or see opportunities for improvements. Feel free to contribute to the project via the [github](https://github.com/flennerhag/mlens) repository! "
   ]
  }
 ],
 "metadata": {
  "_change_revision": 1,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
